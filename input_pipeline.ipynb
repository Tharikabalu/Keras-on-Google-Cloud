{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset object is a Python iterable. This makes it possible to consume its elements using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset:\n",
    "  print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset:\n",
    "  print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by explicitly creating a Python iterator using iter and consuming its elements using next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "it = iter(dataset)\n",
    "print(next(it).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(next(it).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(next(it).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([3, 10]))\n",
    "dataset1.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00404954 0.2389456  0.06523871 0.50624466 0.88319206 0.24818277\n",
      " 0.9167843  0.8961861  0.72291243 0.8221998 ], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.24850297 0.75202084 0.9261923  0.383839   0.34869385 0.27848065\n",
      " 0.9692353  0.83514416 0.28471327 0.1577766 ], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.5283096  0.19883692 0.9244007  0.97104514 0.8017665  0.1745075\n",
      " 0.7995188  0.22323895 0.9560783  0.25470066], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset1:\n",
    "  print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random.uniform([4]),\n",
    "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "\n",
    "dataset2.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23637867 [89 13 59 67 85 19 37 60 90 75 81 14 81 98 48 95 63 55 17 19 10 98 96 50\n",
      " 29 90 51 85 17 43  7 75  2  5 20 23 96 99 74 11 75 40 34 20 22 44 38  2\n",
      "  3 78 18 27 65 14 29 68 74 25 85 30 77 79 97 76 61 70 93 46 56 20 81 48\n",
      " 65 24 86  9 45 72 55 83 88 90 20 31 78 98 77 11 84 19 68 40 97 21 89  2\n",
      " 41 54 76 24]\n",
      "0.41640198 [91 72 82 52 98 61 90 15 12 58 69 72 71 54 87 23 82 35 34 77 18 19 74 95\n",
      " 26 57 53 89 14  9 63 96 67 65 14 56 53  5 69 42 58  2 90  3 74 11  1 22\n",
      " 53 14 96 40 60 84 59 40 28 29 86 14 30 16 54 98  7 67 13 94 94 31 20 58\n",
      "  7 79 74 36 70 87 76 81 92 11 89 59 26 66 22 58 37 37 25 50 88 56 87 87\n",
      " 12 85 68 69]\n",
      "0.062131524 [88  6 31 36 91  8 36 21 37 73  3 16 58 45 55 77 97 18 55 60 68 85 34 57\n",
      " 64 35 48 90 87 75 90 25 11 18  2 30 33 94 47 92 40 37 67 46 37 82 91 85\n",
      " 71 85 22 46 76 54 47 80 54 31 28 24 97 70 89 57 93 20 89 86 65 54 11 90\n",
      " 53 89 37 89 20 70 45 44 58 30 62 70 44 80 46 21 38 34 11 63 32  3 67 53\n",
      " 13 39 42 89]\n",
      "0.64761806 [78 68 52 99 25 63 55 76 36 62 50 28 72 30 70  6 38 97 38 31 88 37 42 33\n",
      " 73 37 31 97  9 17 86 68 97 82 16 73 68 50 56 80 89 13 61 53 65 62 78 21\n",
      " 57  6 88 23 83 99 77 84 26 28 47 70 97 99 64 54 96 20 65 33 35 61  6 65\n",
      " 31 55  3 24 22 64 11 12 48 14 12 26 14 95 40 20 13 29  7 58 66  0 10 46\n",
      "  5 42 84 41]\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset2:\n",
    "  print(elem[0].numpy(),elem[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
       " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00404954 0.2389456  0.06523871 0.50624466 0.88319206 0.24818277\n",
      " 0.9167843  0.8961861  0.72291243 0.8221998 ] (<tf.Tensor: shape=(), dtype=float32, numpy=0.23637866973876953>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([89, 13, 59, 67, 85, 19, 37, 60, 90, 75, 81, 14, 81, 98, 48, 95, 63,\n",
      "       55, 17, 19, 10, 98, 96, 50, 29, 90, 51, 85, 17, 43,  7, 75,  2,  5,\n",
      "       20, 23, 96, 99, 74, 11, 75, 40, 34, 20, 22, 44, 38,  2,  3, 78, 18,\n",
      "       27, 65, 14, 29, 68, 74, 25, 85, 30, 77, 79, 97, 76, 61, 70, 93, 46,\n",
      "       56, 20, 81, 48, 65, 24, 86,  9, 45, 72, 55, 83, 88, 90, 20, 31, 78,\n",
      "       98, 77, 11, 84, 19, 68, 40, 97, 21, 89,  2, 41, 54, 76, 24],\n",
      "      dtype=int32)>)\n",
      "[0.24850297 0.75202084 0.9261923  0.383839   0.34869385 0.27848065\n",
      " 0.9692353  0.83514416 0.28471327 0.1577766 ] (<tf.Tensor: shape=(), dtype=float32, numpy=0.4164019823074341>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([91, 72, 82, 52, 98, 61, 90, 15, 12, 58, 69, 72, 71, 54, 87, 23, 82,\n",
      "       35, 34, 77, 18, 19, 74, 95, 26, 57, 53, 89, 14,  9, 63, 96, 67, 65,\n",
      "       14, 56, 53,  5, 69, 42, 58,  2, 90,  3, 74, 11,  1, 22, 53, 14, 96,\n",
      "       40, 60, 84, 59, 40, 28, 29, 86, 14, 30, 16, 54, 98,  7, 67, 13, 94,\n",
      "       94, 31, 20, 58,  7, 79, 74, 36, 70, 87, 76, 81, 92, 11, 89, 59, 26,\n",
      "       66, 22, 58, 37, 37, 25, 50, 88, 56, 87, 87, 12, 85, 68, 69],\n",
      "      dtype=int32)>)\n",
      "[0.5283096  0.19883692 0.9244007  0.97104514 0.8017665  0.1745075\n",
      " 0.7995188  0.22323895 0.9560783  0.25470066] (<tf.Tensor: shape=(), dtype=float32, numpy=0.062131524085998535>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([88,  6, 31, 36, 91,  8, 36, 21, 37, 73,  3, 16, 58, 45, 55, 77, 97,\n",
      "       18, 55, 60, 68, 85, 34, 57, 64, 35, 48, 90, 87, 75, 90, 25, 11, 18,\n",
      "        2, 30, 33, 94, 47, 92, 40, 37, 67, 46, 37, 82, 91, 85, 71, 85, 22,\n",
      "       46, 76, 54, 47, 80, 54, 31, 28, 24, 97, 70, 89, 57, 93, 20, 89, 86,\n",
      "       65, 54, 11, 90, 53, 89, 37, 89, 20, 70, 45, 44, 58, 30, 62, 70, 44,\n",
      "       80, 46, 21, 38, 34, 11, 63, 32,  3, 67, 53, 13, 39, 42, 89],\n",
      "      dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset3:\n",
    "  print(elem[0].numpy(),elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorSpec(TensorShape([3, 4]), tf.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4]))\n",
    "dataset4.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train\n",
    "images = images/255.0\n",
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.7765\n",
      "Epoch 2/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b92b5deed0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(fmnist_train_ds, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.4171 \n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.5232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b92c7d0650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(fmnist_train_ds.repeat(), epochs=2, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.4433\n",
      "Loss : 0.43952062726020813\n",
      "Accuracy : 0.848716676235199\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(fmnist_train_ds)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8789 - loss: 0.3948 \n",
      "Loss : 0.4057239592075348\n",
      "Accuracy : 0.856249988079071\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(fmnist_train_ds.repeat(), steps=10)\n",
    "print(\"Loss :\", loss)\n",
    "print(\"Accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "(320, 10)\n"
     ]
    }
   ],
   "source": [
    "predict_ds = tf.data.Dataset.from_tensor_slices(images).batch(32)\n",
    "result = model.predict(predict_ds, steps = 10)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydantic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
